{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Gmail_Spam_Detector.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "yJxsMgrZzBDU"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 329,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tYs3etFwuULT"
      },
      "source": [
        "# Importing Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hqxCkgFk0Ycz"
      },
      "source": [
        "df= pd.read_csv(r\"Gmail_Spam_Detector.csv\",encoding= 'unicode_escape')"
      ],
      "execution_count": 330,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "id": "cfLxzRy7v7zn",
        "outputId": "264599e2-760f-4f92-d339-eff3446fe897"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 331,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>type</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spam</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   type                                               text\n",
              "0   ham  Go until jurong point, crazy.. Available only ...\n",
              "1   ham                      Ok lar... Joking wif u oni...\n",
              "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
              "3   ham  U dun say so early hor... U c already then say...\n",
              "4   ham  Nah I don't think he goes to usf, he lives aro..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 331
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "id": "mYOp_jtjwchi",
        "outputId": "5f9d55a5-5ac5-4ffb-aff8-3125a5962323"
      },
      "source": [
        "df['spam'] = df['type'].map({'spam':1,'ham':0}).astype(int)\n",
        "df.head()"
      ],
      "execution_count": 332,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>type</th>\n",
              "      <th>text</th>\n",
              "      <th>spam</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spam</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   type                                               text  spam\n",
              "0   ham  Go until jurong point, crazy.. Available only ...     0\n",
              "1   ham                      Ok lar... Joking wif u oni...     0\n",
              "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...     1\n",
              "3   ham  U dun say so early hor... U c already then say...     0\n",
              "4   ham  Nah I don't think he goes to usf, he lives aro...     0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 332
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2HRc8wsdHEND",
        "outputId": "d587735c-bbc0-4fba-ad7d-d1e8caad2e73"
      },
      "source": [
        "df.shape"
      ],
      "execution_count": 333,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(116, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 333
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GrQdVNhRGZll",
        "outputId": "13e7beeb-6d4d-45ab-d563-df5bd85d5b67"
      },
      "source": [
        "for col in df.columns:\n",
        "    print(col)"
      ],
      "execution_count": 334,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "type\n",
            "text\n",
            "spam\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "id": "s5wEx9MypbYp",
        "outputId": "6d90616b-6593-4325-e602-2c166ae5450c"
      },
      "source": [
        "df = df.drop(['type'],axis=1)\n",
        "df.head()"
      ],
      "execution_count": 335,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>spam</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  spam\n",
              "0  Go until jurong point, crazy.. Available only ...     0\n",
              "1                      Ok lar... Joking wif u oni...     0\n",
              "2  Free entry in 2 a wkly comp to win FA Cup fina...     1\n",
              "3  U dun say so early hor... U c already then say...     0\n",
              "4  Nah I don't think he goes to usf, he lives aro...     0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 335
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aVTBsj94r8mR",
        "outputId": "d7cbeb6e-745d-4702-9a36-267d5f63ed52"
      },
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": 336,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 336
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FtemuLRQuclI"
      },
      "source": [
        "#Data cleaning and preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sb-QzwOKJTc8",
        "outputId": "70d69ab5-0edd-485f-8c7c-fa339d0dd96c"
      },
      "source": [
        "import re\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "ps = PorterStemmer()\n",
        "lemm = WordNetLemmatizer()\n",
        "corpus = []"
      ],
      "execution_count": 337,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2v8QsgJOMdL3"
      },
      "source": [
        "for i in range(0, len(df)):\n",
        "    review = re.sub('[^a-zA-Z]',' ', df['text'][i])\n",
        "    review = review.lower()\n",
        "    review = review.split()\n",
        "    \n",
        "    review = [lemm.lemmatize(word) for word in review if not word in stopwords.words('english')]\n",
        "    review = ' '.join(review)\n",
        "    corpus.append(review)"
      ],
      "execution_count": 338,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EbLLCLSwq44I",
        "outputId": "66e9ed26-0662-44f7-df64-ecf982523a93"
      },
      "source": [
        "corpus"
      ],
      "execution_count": 339,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['go jurong point crazy available bugis n great world la e buffet cine got amore wat',\n",
              " 'ok lar joking wif u oni',\n",
              " 'free entry wkly comp win fa cup final tkts st may text fa receive entry question std txt rate c apply',\n",
              " 'u dun say early hor u c already say',\n",
              " 'nah think go usf life around though',\n",
              " 'freemsg hey darling week word back like fun still tb ok xxx std chgs send rcv',\n",
              " 'even brother like speak treat like aid patent',\n",
              " 'per request melle melle oru minnaminunginte nurungu vettam set callertune caller press copy friend callertune',\n",
              " 'winner valued network customer selected receivea prize reward claim call claim code kl valid hour',\n",
              " 'mobile month u r entitled update latest colour mobile camera free call mobile update co free',\n",
              " 'gonna home soon want talk stuff anymore tonight k cried enough today',\n",
              " 'six chance win cash pound txt csh send cost p day day tsandcs apply reply hl info',\n",
              " 'urgent week free membership prize jackpot txt word claim c www dbuk net lccltd pobox ldnw rw',\n",
              " 'searching right word thank breather promise wont take help granted fulfil promise wonderful blessing time',\n",
              " 'date sunday',\n",
              " 'xxxmobilemovieclub use credit click wap link next txt message click http wap xxxmobilemovieclub com n qjkgighjjgcbl',\n",
              " 'oh k watching',\n",
              " 'eh u remember spell name yes v naughty make v wet',\n",
              " 'fine way u feel way gota b',\n",
              " 'england v macedonia dont miss goal team news txt ur national team eg england try wale scotland txt poboxox w wq',\n",
              " 'seriously spell name',\n",
              " 'going try month ha ha joking',\n",
              " 'pay first lar da stock comin',\n",
              " 'aft finish lunch go str lor ard smth lor u finish ur lunch already',\n",
              " 'ffffffffff alright way meet sooner',\n",
              " 'forced eat slice really hungry tho suck mark getting worried know sick turn pizza lol',\n",
              " 'lol always convincing',\n",
              " 'catch bus frying egg make tea eating mom left dinner feel love',\n",
              " 'back amp packing car let know room',\n",
              " 'ahhh work vaguely remember feel like lol',\n",
              " 'wait still clear sure sarcastic x want live u',\n",
              " 'yeah got v apologetic n fallen actin like spoilt child got caught till go badly cheer',\n",
              " 'k tell anything',\n",
              " 'fear fainting housework quick cuppa',\n",
              " 'thanks subscription ringtone uk mobile charged month please confirm replying yes reply charged',\n",
              " 'yup ok go home look timing msg xuhui going learn nd may lesson',\n",
              " 'oops let know roommate done',\n",
              " 'see letter b car',\n",
              " 'anything lor u decide',\n",
              " 'hello saturday go texting see decided anything tomo trying invite anything',\n",
              " 'pls go ahead watt wanted sure great weekend abiola',\n",
              " 'forget tell want need crave love sweet arabian steed mmmmmm yummy',\n",
              " 'rodger burn msg tried call reply sm free nokia mobile free camcorder please call delivery tomorrow',\n",
              " 'seeing',\n",
              " 'great hope like man well endowed lt gt inch',\n",
              " 'call message missed call',\n",
              " 'get hep b immunisation nigeria',\n",
              " 'fair enough anything going',\n",
              " 'yeah hopefully tyler could maybe ask around bit',\n",
              " 'u know stubborn even want go hospital kept telling mark weak sucker hospital weak sucker',\n",
              " 'thinked first time saw class',\n",
              " 'gram usually run like lt gt half eighth smarter though get almost whole second gram lt gt',\n",
              " 'k fyi x ride early tomorrow morning crashing place tonight',\n",
              " 'wow never realized embarassed accomodations thought liked since best could always seemed happy cave sorry give sorry offered sorry room embarassing',\n",
              " 'sm ac sptv new jersey devil detroit red wing play ice hockey correct incorrect end reply end sptv',\n",
              " 'know mallika sherawat yesterday find lt url gt',\n",
              " 'congrats year special cinema pas call c suprman v matrix starwars etc free bx ip pm dont miss',\n",
              " 'sorry call later meeting',\n",
              " 'tell reached',\n",
              " 'yes gauti sehwag odi series',\n",
              " 'gonna pick burger way home even move pain killing',\n",
              " 'ha ha ha good joke girl situation seeker',\n",
              " 'part checking iq',\n",
              " 'sorry roommate took forever ok come',\n",
              " 'ok lar double check wif da hair dresser already said wun cut v short said cut look nice',\n",
              " 'valued customer pleased advise following recent review mob awarded bonus prize call',\n",
              " 'today song dedicated day song u dedicate send ur valuable frnds first rply',\n",
              " 'urgent ur awarded complimentary trip eurodisinc trav aco entry claim txt dis morefrmmob shracomorsglsuplt l aj',\n",
              " 'hear new divorce barbie come ken stuff',\n",
              " 'plane give month end',\n",
              " 'wah lucky man save money hee',\n",
              " 'finished class',\n",
              " 'hi babe im home wanna something xx',\n",
              " 'k k performed',\n",
              " 'u call',\n",
              " 'waiting machan call free',\n",
              " 'thats cool gentleman treat dignity respect',\n",
              " 'like people much shy pa',\n",
              " 'operate lt gt',\n",
              " 'still looking job much ta earn',\n",
              " 'sorry call later',\n",
              " 'k call ah',\n",
              " 'ok way home hi hi',\n",
              " 'place man',\n",
              " 'yup next stop',\n",
              " 'call later network urgnt sm',\n",
              " 'real u getting yo need ticket one jacket done already used multis',\n",
              " 'yes started send request make pain came back back bed double coin factory gotta cash nitros',\n",
              " 'really still tonight babe',\n",
              " 'ela kano il download come wen ur free',\n",
              " 'yeah stand close tho catch something',\n",
              " 'sorry pain ok meet another night spent late afternoon casualty mean done stuff moro includes time sheet sorry',\n",
              " 'smile pleasure smile pain smile trouble pours like rain smile sum hurt u smile becoz someone still love see u smiling',\n",
              " 'please call customer service representative pm guaranteed cash prize',\n",
              " 'havent planning buy later check already lido got show e afternoon u finish work already',\n",
              " 'free ringtone waiting collected simply text password mix verify get usher britney fml po box mk h ppw',\n",
              " 'watching telugu movie wat abt u',\n",
              " 'see finish load loan pay',\n",
              " 'hi wk ok hols yes bit run forgot hairdresser appointment four need get home n shower beforehand cause prob u',\n",
              " 'see cup coffee animation',\n",
              " 'please text anymore nothing else say',\n",
              " 'okay name ur price long legal wen pick u ave x am xx',\n",
              " 'still looking car buy gone driving test yet',\n",
              " 'per request melle melle oru minnaminunginte nurungu vettam set callertune caller press copy friend callertune',\n",
              " 'wow right mean guess gave boston men changed search location nyc something changed cuz signin page still say boston',\n",
              " 'umma life vava umma love lot dear',\n",
              " 'thanks lot wish birthday thanks making birthday truly memorable',\n",
              " 'aight hit get cash',\n",
              " 'would ip address test considering computer minecraft server',\n",
              " 'know grumpy old people mom like better lying always one play joke',\n",
              " 'dont worry guess busy',\n",
              " 'plural noun research',\n",
              " 'going dinner msg',\n",
              " 'ok wif co like try new thing scared u dun like mah co u said loud',\n",
              " 'gent trying contact last weekend draw show prize guaranteed call claim code k valid hr ppm',\n",
              " 'wa ur openin sentence']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 339
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2AZetT98umPe"
      },
      "source": [
        "#CountVectorizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K89hJAkKNAhY"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "cv = CountVectorizer(max_features = 5000)\n",
        "X = cv.fit_transform(corpus).toarray()\n",
        "\n",
        "y = pd.get_dummies(df['text'])\n",
        "y=y.iloc[:,1].values"
      ],
      "execution_count": 340,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NUWUp0wNvcxK"
      },
      "source": [
        "#Splitting the data into train and test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g85sTw64NEzn"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.2,  random_state=0)"
      ],
      "execution_count": 341,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lJ_Q_7wdug2A"
      },
      "source": [
        "#Training model using Naive Bayes Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JNaNs7WNNgkQ",
        "outputId": "5b877005-3241-4afe-b145-6de55349a7e3"
      },
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "mnb = MultinomialNB().fit(X_train, y_train)\n",
        "y_pred = mnb.predict(X_test)\n",
        "accuracy_score(y_test, y_pred)"
      ],
      "execution_count": 342,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9583333333333334"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 342
        }
      ]
    }
  ]
}